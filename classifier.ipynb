{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e9d5f57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train dataset...\n",
      "loading test dataset...\n",
      "building model...\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 25s 82ms/step - loss: 0.1815 - categorical_accuracy: 0.8336\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 24s 82ms/step - loss: 0.0343 - categorical_accuracy: 0.9545\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 26s 86ms/step - loss: 0.0226 - categorical_accuracy: 0.9693\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 26s 85ms/step - loss: 0.0170 - categorical_accuracy: 0.9769\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 25s 82ms/step - loss: 0.0140 - categorical_accuracy: 0.9807\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.0127 - categorical_accuracy: 0.9815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: classifier.ai/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: classifier.ai/assets\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def encodeNum(x):\n",
    "    \n",
    "    template = [0,0,0,0,0,0,0,0,0,0]\n",
    "    template[x] = 1\n",
    "    return template\n",
    "    \n",
    "def decodeNum(x):\n",
    "    \n",
    "    return x.index(max(x))\n",
    "    \n",
    "def loadDataset(test=False):\n",
    "    \n",
    "    (X, Y), (X_test, Y_test) = mnist.load_data()\n",
    "    \n",
    "    \n",
    "    Y_encoded = []\n",
    "    \n",
    "    if not test:\n",
    "        print('loading train dataset...')\n",
    "        #encoding \n",
    "        for unencoded_label in Y:\n",
    "            encodedNum = encodeNum(unencoded_label)\n",
    "            Y_encoded.append(encodedNum)\n",
    "        \n",
    "        return X, np.array(Y_encoded)\n",
    "\n",
    "    else:\n",
    "        #encoding \n",
    "        print('loading test dataset...')\n",
    "        for unencoded_label in Y_test:\n",
    "            encodedNum = encodeNum(unencoded_label)\n",
    "            Y_encoded.append(encodedNum)\n",
    "        \n",
    "        return X_test, np.array(Y_encoded)    \n",
    "    \n",
    "\n",
    "\n",
    "def buildModel():\n",
    "    #define model\n",
    "    print('building model...')\n",
    "    \n",
    "    classifier = Sequential()\n",
    "\n",
    "    #input\n",
    "    classifier.add(Input(shape=(28,28,1)))\n",
    "\n",
    "    #hidden\n",
    "    classifier.add(Conv2D(32,(3,3),padding=\"same\"))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2),padding=\"same\"))\n",
    "    classifier.add(Dropout(0.1))\n",
    "    \n",
    "    classifier.add(Conv2D(16,(4,4),padding=\"same\"))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2),padding=\"same\"))\n",
    "    \n",
    "    classifier.add(Flatten())\n",
    "    \n",
    "    classifier.add(Dense(72,activation=\"relu\"))\n",
    "    classifier.add(Dense(36,activation=\"relu\"))\n",
    "\n",
    "    #output\n",
    "    classifier.add(Dense(10, activation=\"softmax\"))\n",
    "    \n",
    "    \n",
    "    #compile\n",
    "    classifier.compile(loss = 'binary_crossentropy', run_eagerly=True ,optimizer = 'adam', metrics=[metrics.CategoricalAccuracy()])\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "images, labels  = loadDataset()\n",
    "test_images , test_labels = loadDataset(test=True)\n",
    "\n",
    "classifier = buildModel()\n",
    "classifier.fit(x=images,y=labels,batch_size = 200,epochs=5,verbose=\"auto\",shuffle=True)\n",
    "classifier.evaluate(x=test_images,y=test_labels)\n",
    "\n",
    "\n",
    "classifier.save('classifier.ai')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a896e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca729c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a40628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
