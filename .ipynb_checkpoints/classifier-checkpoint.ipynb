{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e9d5f57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test dataset...\n",
      "building model...\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 7s 24ms/step - loss: 0.1147 - categorical_accuracy: 0.8053\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 7s 24ms/step - loss: 0.0280 - categorical_accuracy: 0.9605\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 7s 23ms/step - loss: 0.0180 - categorical_accuracy: 0.9744\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 7s 24ms/step - loss: 0.0137 - categorical_accuracy: 0.9810\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 7s 25ms/step - loss: 0.0112 - categorical_accuracy: 0.9847\n",
      "validate...\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0149 - categorical_accuracy: 0.9764\n",
      "test...\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.0082 - categorical_accuracy: 0.9902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: classifier.ai\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: classifier.ai\\assets\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def encodeNum(x):\n",
    "    \n",
    "    template = [0,0,0,0,0,0,0,0,0,0]\n",
    "    template[x] = 1\n",
    "    return template\n",
    "    \n",
    "def decodeNum(x):\n",
    "    \n",
    "    return x.index(max(x))\n",
    "    \n",
    "def loadDataset():\n",
    "    \n",
    "    \n",
    "    print('loading test dataset...')\n",
    "    (XT, YT), (XV, YV) = mnist.load_data()\n",
    "    \n",
    "    X_validate, X_test = np.split(XV,2)\n",
    "    Y_validate_raw, Y_test_raw = np.split(YV,2)\n",
    "    \n",
    "    \n",
    "    Y_train = []\n",
    "    Y_validate = []\n",
    "    Y_test = []\n",
    "    \n",
    "\n",
    "    for unencoded_label in YT:\n",
    "        encodedNum = encodeNum(unencoded_label)\n",
    "        Y_train.append(encodedNum)\n",
    "        \n",
    "\n",
    "    for unencoded_label in Y_validate_raw:\n",
    "        encodedNum = encodeNum(unencoded_label)\n",
    "        Y_validate.append(encodedNum) \n",
    "\n",
    "\n",
    "    for unencoded_label in Y_test_raw:\n",
    "        encodedNum = encodeNum(unencoded_label)\n",
    "        Y_test.append(encodedNum)\n",
    "        \n",
    "    return ((XT/255,np.array(Y_train)),(X_validate/255,np.array(Y_validate)),(X_test/255,np.array(Y_test)))\n",
    "    \n",
    "\n",
    "\n",
    "def buildModel():\n",
    "    #define model\n",
    "    print('building model...')\n",
    "    \n",
    "    classifier = Sequential()\n",
    "\n",
    "    #input\n",
    "    classifier.add(Input(shape=(28,28,1)))\n",
    "\n",
    "    #hidden\n",
    "    classifier.add(Conv2D(32,(3,3),padding=\"same\"))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2),padding=\"same\"))\n",
    "    classifier.add(Dropout(0.1))\n",
    "    \n",
    "    classifier.add(Conv2D(32,(3,3),padding=\"same\"))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2),padding=\"same\"))\n",
    "    \n",
    "    classifier.add(Flatten())\n",
    "    \n",
    "    classifier.add(Dense(72,activation=\"relu\"))\n",
    "    classifier.add(Dense(36,activation=\"relu\"))\n",
    "\n",
    "    #output\n",
    "    classifier.add(Dense(10, activation=\"softmax\"))\n",
    "    \n",
    "    \n",
    "    #compile\n",
    "    classifier.compile(loss = 'binary_crossentropy', run_eagerly=True ,optimizer = 'adam', metrics=[metrics.CategoricalAccuracy()])\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "\n",
    "\n",
    "(images_train, labels_train), (images_validate, labels_validate), (images_test, labels_test) = loadDataset()\n",
    "\n",
    "classifier = buildModel()\n",
    "classifier.fit(x=images_train,y=labels_train,batch_size = 200,epochs=20,verbose=\"auto\",shuffle=True)\n",
    "\n",
    "\n",
    "print(\"validate...\")\n",
    "classifier.evaluate(x=images_validate,y=labels_validate)\n",
    "\n",
    "print(\"test...\")\n",
    "classifier.evaluate(x=images_test,y=labels_test)\n",
    "\n",
    "classifier.save('classifier.ai')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a896e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca729c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a40628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.9 *tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
